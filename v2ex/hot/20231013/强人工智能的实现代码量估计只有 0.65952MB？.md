### 强人工智能的实现代码量估计只有 0.65952MB？

现在没有出现强人工智能，但是有强智能的人类可以参考。
一个碱基对有 4 中可能，计算机的一个位有 0 ，1 两种可能。
32 亿碱基对就算全是有效信息也就
32 亿×2/8/1024/1024 = 762.94MB
其中人的 DNA 有效基因不会超过 10%，有很多没表达的基因
762.94×10% = 76.294 MB
还有 DNA 翻译成蛋白质会造成信息的损失（要 3 个碱基对确定 20 个氨基酸构成蛋白质）
76.294×log64 （ 20 ） = 54.96MB
人和大猩猩基因相似度大约 98.8%，粗略的将差异的 1.2%当成导致智能差异的基因，估计人智能所需的信息量只有
54.96*1.2% = 0.65952MB
计算和实际的误差应该挺大的，但是数量级差不多了。
为什么这么小的信息量现在还无法在计算机中模拟出强人工智能？难道瓶颈在显存和算力而不是算法上？
假设一滴水的水分子只有像 0 和 1 的两种状态数据量就达到了，
1.67 * Math.pow(10,21)/8/1024/1024/1024/1024 = 189857019 TB
还有现实中的数据大多是连续的无理数，而计算机只能进行离散的有理数进行存储计算导致丢失精度。
所以还是要堆存储算力或者改计算机的底层设计（像量子计算机）才可能实现强人工智能吗?

---------------------------------------------------

不懂人工智能，也不懂生物，吃瓜群众，给你顶下

---------------------------------------------------

我猜可能和真随机有关

---------------------------------------------------

不能实现的根本原因还是不理解为什么，现在也只是进行模拟生物神经元，但是为什么这样就可以有智能，实际上没有研究透彻，会导致没有办法随心改进，根据原理实现，当然现在计算机的设计也导致了不能更强原因。所以现在有科学家培育生物神经元进行机器学习

---------------------------------------------------

人和大猩猩基因相似度大约 98.8%，粗略的将差异的 1.2%当成导致智能差异的基因

你吃饱饭是因为最后那一口，前面的都可以不吃

---------------------------------------------------

现在的问题不是代码，毕竟基因组已经测序完毕了。现在的问题是怎么把代码从碳基运行时移植到硅基运行时。在碳基运行时的代码很小不代表相同的功能到硅基运行时也很小。

---------------------------------------------------

其中人的 DNA 有效基因不会超过 10%，有很多没表达的基因——有效基因这种概念似乎不太合适，即使是不表达的基因本身也可能参与启动子、增强子、基因沉默区域，以及在遗传的过程中发生突变以后，也可以重新直接参与表达。

DNA 翻译成蛋白质会造成信息的损失——实际上不存在信息的丢失，反而在翻译过程增加了信息的复杂度，翻译过程中 rna 和蛋白质都有各种相互变化和作用，可以直接影响最后的基因功能

以及 3d 基因组、表观遗传这些东西，实际上也说明现代遗传学作为一门类似逆向研究工程，还存在大量未知的领域。

---------------------------------------------------

先不说你这个思路对不对，即使你是对的，你这算的是硬件啊，相当于用多大的存储可以完全描述 cpu 和硬盘的信息

---------------------------------------------------

地球从无生命到有生命花了几亿年，有生命到有文明花了几百万年，有文明到信息文明花了几千年。初略的将信息文明当作地球存在文明的证明，换算得出地球从无生命到有信息文明花了几千年。

---------------------------------------------------

不懂人工智能，不懂生物，吃瓜群众，随便唠唠。

你这个计算的前提是，智能是基因形成并运行的，这个前提是对的么？比如我保存电脑的设计图，假设文档图纸一共 1 个 t 吧，某个完全没见过电脑的文明知道这个数据量能再造一台么？相对于一个文明，t 应该不是一个很大的量级，但关键是不是可能不在量级上？

---------------------------------------------------

@linksNoFound 不算最后一口，那全算下去也才 762.94MB

---------------------------------------------------

也来随便唠唠。。
DNA 表达也要依赖现实世界的蛋白质等物质的实际特性。
就像你用高级语言写一段程序，几行代码就能表达复杂的功能，但它后面编译器和运行环境是一大坨东西，远超源代码的大小。

---------------------------------------------------

我想的是计算机只是模拟人神经网络，不能把人脑与计算机数据量 画等号

---------------------------------------------------

是，可执行文件就这么大，但是运行时你都不考虑下么，DNA 的运行时，转录出来的蛋白质之间的作用机制，还有各种理化生物机理，外界环境刺激的机理巴拉巴拉，这个运行时做好了，DNA 也就可执行了。。。

---------------------------------------------------

DNA 可能是一个压缩文件包，要解压后才能运行，我们不知道压缩包的算法，所以尚未知道压缩文件包实际有多大

---------------------------------------------------

@cxtrinityy 如果设计图包含的信息足够是可以做的，毕竟之前我下载的中文书库才 800g ，而且如果是人 dna 的信息要在计算机中模拟一个人很难，但是现实世界用克隆技术做一个反而很容易。

---------------------------------------------------

楼主只考虑到“信息”本身占用的存储量，没有考虑到“生命”的本质是细胞核。细胞核生产使用 dna （实际上是 rna 转录）产生蛋白质，蛋白质组成酶，再通过化学和物理反应产生能量，能量维持生命体循环，构成细胞核，单细胞生物，再到多细胞，最后才有复合生物体，发展出器官组织生命形态。这里面是一整套东西啊，单单把 dna 提取出来扔原始海洋汤里也不会有生命出现，更别提生成孕育智能生命体了。

所以真要类比，楼主的意思是，写多少行代码能让计算机实现自己造出 cpu ，内存，硬盘，然后不断进化成一个房子（略微类似于一个细胞核），再扩展成能自我复制繁衍的生命体。然后再考虑怎么进化吧。

---------------------------------------------------

0.65952MB 应该是设计图纸 or 设计文档的最小大小，实际产物肯定不止，智能最后来源于细胞蛋白质什么的，dna 保存的只是的设计

---------------------------------------------------

"""
还有 DNA 翻译成蛋白质会造成信息的损失（要 3 个碱基对确定 20 个氨基酸构成蛋白质）
76.294×log64 （ 20 ） = 54.96MB
"""
这里不是这么算的吧
32 亿碱基对可以确认 32 亿/3 个氨基酸
又氨基酸共有 20 种可能
包含的信息不应该是 20 ** (32 亿/3) 
这个数字就巨大无比了

---------------------------------------------------

楼上没有一个人学过初中数学？ 32 亿碱基对，有效组合是 pow(4, 3.2B)

IPv4 地址有多少个？是 256 + 256 + 256 + 256 么？

---------------------------------------------------

你的大脑里只有一个 DNA ？？？
就算 DNA 是核心算法，还得有个操作系统，这个操作系统深度定制的只支持 DNA 这种算法。要一起算进去才行。

---------------------------------------------------

即便这玩意存起来 storage 只有 1GB ，但是如果每个 bit 都是有效信息，排列组合的 Cartesian 也是无穷多的。类似于现在的 DL 一个模型的所有权重可以任意排列组合任意连接，并不是能通过 on-disk 大小估计的巨大数量级

---------------------------------------------------

不能这么算吧，至少得考虑工程上的实现吧 :(
---------
0.源码来看，基因只算部分源码，类比到计算机编译/连接，大脑发育过程，那外部环境肯定有影响，这也得算源码，并且数量级也不好估计，所以 OP 算的这个源码不全对吧 :)

1.基因+外部环境+???，"编译链接"后，生成的大脑输出的可能性太多了，类比计算机，至少得编译出个现代操作系统吧？那可以参考下操作系统的源码量，当然也可以源码足够小，但压力就到了编译器/连接器，相当于给编译工具里赛了个操作系统源码。

2.围棋在二维平面，就 19*19+黑白两子，棋盘局面数太大，大到无法暴力穷举, 人脑还是三维立体结构，复杂度和生物信号远超两种，而且还有冲激信号这种，用计算机的 0 、1 来表示比较复杂，人脑输出可能性也远超围棋 :(

3.现在也没研究透人脑，用计算机来实现，可能类似盲人摸象? 实现还是算法来部分模拟，没用暴力穷举 :)

---------------------------------------------------

@ahhui 我估计不是代码量的问题，是要有很大的算力和存储才能实现。
原始海洋汤里，只要有足够多的时间和数量就回有生命出现，虽然这是天文数字。
分子总是做无规则的布朗运动，但是只要有足够久的时间这个运动可能就把对应的分子放对对应的位置，抽出来的 dna 正好构成了一个细胞核使生命出现。

---------------------------------------------------

你这算的是信息存储容量。

人的智慧来自大脑神经元，基因只是存储了基础组件的信息，所需的信息量可以比较小。组件之间排列组合，那就是海量的了。

我看有的说法是大脑属于非经典计算机，这可能关系到意识与存在的问题

---------------------------------------------------

人和大猩猩基因相似度大约 98.8%，粗略的将差异的 1.2%当成导致智能差异的基因，估计人智能所需的信息量只有
54.96*1.2% = 0.65952MB

也许并不是这多出来的 1.2 帕实现了智能，
只是这 1.2 帕是智能的必要条件（核心逻辑），
其他的 98.8 帕也参与计算。只不过他们是基础设施而已！

---------------------------------------------------

dna===代码
染色体===项目
细胞核===编译器
细胞===服务器

---------------------------------------------------

把 DNA 比作可执行文件的话
DNA 的运行时（现实世界）也是一个非常复杂的东西，包含了物理化学生物的各种作用的模拟
启动运行的初始条件如当前细胞各种细胞器状态，细胞液状态，周围环境等等，都是必要的初始条件。
另外，700MB 的无依赖 binary ，携带的信息量是极其巨大的。chrome 我查了一下代码行近 3000 万，windows binary<300MB 。

---------------------------------------------------

你这逻辑怎么这么奇怪呢？
人不是生下来就有智能的，一个初生的小孩让大猩猩捡回去养，养到成年，你觉得他有你理解里的“智能”么？
你觉得他缺那 1.2%的基因么？
智能，是指人类文明信息，运行在人脑操作系统上的一种表现
你懂么？人是人类文明的载体，而不是文明本身

---------------------------------------------------

@pkoukk 反过来把大猩猩当人养也不会具备人的智能，硬件就被限制了了。
还有人脑是操作系统，那计算机为什么不能像虚拟机一样模拟这个操作系统然后学习人类的文明信息？

---------------------------------------------------

@fanym #29 
1 、你只能说猩猩硬件性能差，不能说完全没有，有不少猩猩表现出的学习能力和理解能力并不低。
你甚至能看到不少“能上大学”的边牧。只能说人类信息系统没有对猩猩的硬件做优化。
2 、你说的这玩意，就是神经元网络和当代 AI 模型的起源思想

---------------------------------------------------

DNA 只是数据，不表达任何信息，需要依靠蛋白质表达，就像人不是从 DNA 中出生，而是从受精卵出生。蛋白质的复杂性相当高。
但是这种不利用机器特性而强行拟人的做法，我估计最后诞生的只能是虚拟人，没有什么超越人类的智能。
如果只模拟神经元，那就与 DNA 无关，比如模拟一个线虫，302 个神经元： https://github.com/openworm/OpenWorm

---------------------------------------------------

你这个只是基础框架包的容量吧，或者说是整个系统一个细小模块。 依赖库，操作系统这些没算进去。

---------------------------------------------------

@fanym 那为啥美国要用光刻机卡中国芯片的脖子？中国企业是不会生产手机么？
当你说信息足够时，你说的可不仅仅是电脑的信息，这里包含了上下游所有涉及领域的知识。
克隆技术本身依然使用的是现成的生物基础，这就像你可以在代码里调库但完全不知道实现只需要明白 API ，而当你说要用计算机模拟智能时，你是要抛弃一切基础，只有你明白了整个原理，你才能使用完全不同的语言不看源码再写一个一样功能的库。

---------------------------------------------------

@ytgui #19 模拟的是一个人，而不是所有人。不需要穷尽所有组合，只需要一个正常人的确定的基因序列。

---------------------------------------------------

好问题啊，有时不禁想人类的大脑是不是某类预训练了 20 万年的大模型，并且边训练边剪枝来控制模型大小。DNA 只是代际传递的隐变量，在下一个代际初始化后，由上一代和周围的社会族群带领进行知识蒸馏，在学习并收敛到一定的稳定态之后再逐渐开始自监督学习。隐变量可以维度很低容量很少，后续的代际间指导和自我学习才是人类大脑这堆屎山代码迭代出强智能的主要原因

---------------------------------------------------

思路不错. 但是不要脱离外部环境. 
生物多样性是 自身 DNA+地球环境共同决定的. 拥有完美呼吸系统的强人工智能去到没氧气的外星球会立刻挂掉

就好比你手里有一把钥匙, 面前有两扇门. 成功打开左门, 里面是个图书馆.
那钥匙的信息量是 1bit? 2bit? 还是 1Pbit?

---------------------------------------------------

不如说是，运行强人工智能的硬件设计图纸只需要 762.92mb 。

---------------------------------------------------

按这种思考方式来说，这所谓的 0.65952MB 是纯文本源码的大小啊，实际编译出的大小估计整个宇宙的粒子都无法穷尽。
实现功能直接靠蛋白质，蛋白质的合成才是 DNA 控制。
蛋白质的种类繁多到难以置信，每个蛋白质的结构也复杂的惊人。
DNA 的转录翻译就类似于把这 0.6MB 的文本放在自然环境中编译出一个有完整功能的人类，还要考虑到编译环境对源代码的自然选择，一边编译，一边改造环境，一边反作用于源码。
最后好不容易编译完了，还要考虑别的编译产物对自身源代码的影响，也就是“文化”。
而文化本身也是个极为复杂的互相影响的系统，“文化”这个系统套”蛋白质“再套”DNA“，最简单的计算也是蛋白质的所有可能性*DNA 所有可能性*文化影响的所有可能性。
放过计算机吧，它就是个加减乘除的重复计算机器而已，不是上帝。

---------------------------------------------------

有些定义解读是各自不同的，但实际可能和任何一种解读都背离，因为所有解读的人（或者说时代）都没达到足够的水平

例如：ABC 和 CBA 相似度的解读，按字母解读就是 100%相同，但所有懂英语的人都知道不能这样解读（达到足够的水平），所以能确认它们是不同的

---------------------------------------------------

打包后的代码是 0.6M ，运行这段代码的环境是多大，里面各种组件 各种工具都还没实现。

---------------------------------------------------

智能和大脑有关，你得算有多少神经元，他们的连接方式，他们从出生开始获取了多少的信息，这些信息以脑细胞的不同刺激记忆了下来，形成了一个复杂的大网。

基因大概就是类似种子的或者磁力链接。大脑每一个细胞的状态才是你要下载运行的软件

---------------------------------------------------

这两者对比本来就不太合适吧?
虽说 碱基对就那些,但生物存在蛋白质生成和作用的过程,并且很依赖物理规则,目前这个人类还没完全摸清,这可以算是一个混沌系统
程序可不一样,这是一个明确的逻辑系统,很大可能不存在这么复杂的规则
即便我们当他是一个函数,用神经网络去拟合,那也不一定跟人类的思维方式一样
可能是一种人类无法理解的规则或方式
这也是哲学的一个老生常谈的问题:怎样才算是拥有"思考"和"生命"

---------------------------------------------------

按楼主的算法，我一行 new AI()就写完了

---------------------------------------------------

一个碱基对有 4 中可能，计算机的一个位有 0 ，1 两种可能。
32 亿碱基对就算全是有效信息也就
32 亿×2/8/1024/1024 = 762.94MB
毫无逻辑的描述

---------------------------------------------------

人类一思考，上帝都在笑

---------------------------------------------------

你这算得似乎有些问题。
既然每个碱基对有 4 种可能,每个计算机位有 2 种可能,我们可以这样看:

- 碱基对数量为 32 亿个
- 每个碱基对有 4 种可能
- 等同于用 32 亿个计算机位来表示,每个位有 2 种可能

那么总的可能组合就是:

2^32,000,000,000

即 32 亿个计算机位,每个位独立取值为 0 或 1,所以总共有 2 的 32 亿次方种组合可能。

所以答案是:
2^32,000,000,000

每增加一个计算机位,可能性就增加一倍;32 亿个计算机位,可能性就是 2 的 32 亿次方。

---------------------------------------------------

基因是 data 吧

---------------------------------------------------

@webcape233 漏了似乎次方还要✖️2 ，渣数学

---------------------------------------------------

基因只是为了遗传跟繁殖吧，跟智能有关系吗？基因只是生产出了神经系统跟肌肉还有骨骼等等。神经系统所有细胞如果是初始化状态，那就是白痴。就像 1 亿参数的大模型，如果所有参数都还是初始化的 0 状态，一步也没有训练过，那就是无智能。
基因只是生产出足够多初始化的神经系统以便训练而已。这个过程也仅仅是你初始化了一个 1 亿参数的模型空间，你初始化一秒钟完成了，但生物需要分裂繁殖很长时间。
就像一块空硬盘，你不能说这个硬盘能存储 1 亿参数的大模型，所以这个硬盘就是人工智能硬盘。

---------------------------------------------------

DNA 怎么翻译成氨基酸，氨基酸组合成肽链，再折叠成蛋白质，这些过程中也不是不包含信息。比如，AGCT 对应某种氨基酸，存储这个映射也是要信息。DNA 是编码后的文件，需要解码器翻译成蛋白质，计算信息不能只计算编码后的信息量，仅凭它是无法恢复的。

---------------------------------------------------

@qiyilai 这里几乎都是程序员，还要把计算机存储原理说下吗？
计算机一个位是 0 和 1 ，一个碱基对有 4 种可能也就是有 2 个位的信息所以乘以 2 ，
8 个位一个字节所以除 8 得到字节数，
除 1024 得到 KB ，
再除 1024 得到 MB.

---------------------------------------------------

天才和傻子基因几乎 100%相同，因此人工智能实现的代码量约等于 0

---------------------------------------------------

不知所云。
DNA 是遗传物质，是蛋白质表达的基础（反映到软件工程上是源代码），并不是信息总量。

google 的主页也才 800KB 而已，难道全互联网的信息总量是 800KB 吗？

建议楼主了解一下二维元胞自动机(2D Cellular Automata)

---------------------------------------------------

建议发到百度弱智吧

---------------------------------------------------

GPT10 的本体

---------------------------------------------------

估计快到超级智能了

---------------------------------------------------

这个思路错得离谱。

人类是基于动物的非动物。
人类的智能主要体现在后天学习和社会化合作上面，这些都不是在基因层面表达的。
你把一个人类幼儿扔进狼群长大，压根就不会有比狼更高的智能产生。

所以，以成人智能为参照的所谓强人工智能，完全不能以基因的编码量来衡量。
如果是以成年人的脑部神经元数量来衡量可能还靠谱点。

---------------------------------------------------

@ytgui 你才是算错了，你当基因上的是量子信息呐？量子信息才算笛卡尔积（张量积）

---------------------------------------------------

这就是为什么出现了碳基高级生命却没有出现硅基生命的原因了。

---------------------------------------------------

别的先不说，碱基对相当于 1010 ，代码可是给人看的，所以碱基对应该对应二进制文件，然后，基因是生物这个操作系统的程序，生物系统有各种物理化学光电等等底层，电脑却没有这么复杂的系统。再者，校验码不参与工作也不重要吗😏

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

---------------------------------------------------

众所周知，运行一段最简单的 HelloWorld 主程序只需要几行，存储只需要几 kb

按你的计算理解：

编译器可以不要
主操作系统可以不要
各硬件的 BIOS 可以不要
硬件中的电路也可以不要

不算上述内容，你还没有算你编码逻辑的信息量？如何计算编码逻辑的信息量？

你需要的是信息，而不是🐒敲键盘

---------------------------------------------------

要区分两个概念，DNA 中的信息量算是强人工智能的“代码”（.py 文件），而不是完整模型（包括训练完成之后的参数），后者的信息量要大很多。

---------------------------------------------------

没准训练数据和算力管够的话用最简单的神经网络结构就能训练出强人工智能。

---------------------------------------------------

一个正常发育的人神经元大约在 1e11 个的量级，相当于 1e11 个处理单元同时运行这个代码。不管程序多简单，目前可没有什么计算设备有这么多处理单元。

---------------------------------------------------

@mkoijnbhu #61 我感觉你这个方向不对。你说的那些东西中很多可能都是对强人工智能没用的，或者就是很多都是为了提高效率的无奈之举。在绝对高的算力下可能用简单的算法就能实现非常复杂的功能。再加上强人工智能应该会包含自我优化的能力，强人工智能自己设计出来的算法不算代码吧？

---------------------------------------------------

这个代码量只是 DNA 这个 Domain Specific Language 的代码量，基础设施的代码量完全忽略了啊。
别的不说，运行时你打算怎么统计？从量子理论先实现到大统一模型吧，要不你先算算这个代码量？

---------------------------------------------------

@fanym 是的，你说的都对

---------------------------------------------------

但是现在的人工智能在通用领域不一定有大猩猩聪明

---------------------------------------------------

光看主贴内容，我凭直觉感觉是民科，但是仔细思考后，我发现要解释其中的谬误对我来说还挺困难的。我尝试把我目前的思考结果贴出来吧。

我认为 op 谬误的本质是误解了信息熵的意义，以为信息熵与现实世界存在对应关系。首先什么是所谓的“代码大小”，其实本质就是在古典概型下信息熵的大小，即所有等概率事件数量的对数。比如说 2 bit 的数据可以代表其为 4 种可能的结果之一； 16 种可能的结果就需要 4 bit 的信息描述；一张 3.5 寸软盘 (1440 KiB) 能保存 2^(1,440,000 * 8) 种不同可能的结果；而假设碱基对出现的可能性均等，人的 DNA 的信息熵约为 log2(4^(32 * 10^8)) ≈ 762.94 * 1024 * 1024 * 8 bit 。到这里为止，op 是正确的。然而，信息熵的意义只能停止于此。

要给一段信息赋予意义，我认为关键在于：在样本空间（即所有可能结果的集合）中，这个事件（特定组合的“代码”信息）“出现”后，它作为因产生了哪些果。这里无法避免现实世界的复杂性，op 忽略了这部分就产生了不可理喻的谬误。例如一段 Python 代码文件“出现”后，其通过标准架构计算机读取到内存中，由 IDE 执行就变成了屏幕上显示的代码，由错误的解释器执行就显示为某 error ，由正确的解释器就产生代码作者设计的执行结果；我发的这段文本编码为几 KiB 的二进制流“出现”在服务器中之后，电子设备和现代浏览器正确解码并渲染为文字图像，由一个能够熟练阅读中文的网友阅读、理解并作出了后续行动；一个人类的 DNA 序列“出现”后，从受精卵到拥有智力的成人需要保持适宜的环境、适量的营养摄入以及现代社会的培养等等无数数不清的细节。

再举一个极端的例子，按照 op 的逻辑，假设存在一个已经实现的人工智能，有一个总电源开关控制它，难道说这个人工智能只需要这 1 bit 的数据量就可以实现了？

TLDR: 数据量仅代表样本空间的大小，它并不能直接反映现实世界的复杂性。将样本空间中的事件（“代码”）强行与现实联系起来是荒谬的。

